{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMIP6 Interactive Comparison Tool\n",
    "\n",
    "This notebook provides interactive visualization of ISMIP6 NetCDF data using HoloViews.\n",
    "\n",
    "Features:\n",
    "- Load data directly from Google Cloud Storage\n",
    "- Compare multiple models and experiments\n",
    "- Linked zooming and panning across all plots\n",
    "- Interactive time slider\n",
    "- Colorbar synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "from holoviews import opts\n",
    "import panel as pn\n",
    "from ismip6_index import get_file_index\n",
    "from grid_utils import correct_grid_coordinates\n",
    "\n",
    "# Initialize HoloViews with bokeh backend\n",
    "hv.extension('bokeh')\n",
    "pn.extension()\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Specify the variable, experiments, and models to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VARIABLE = 'sftflf'  # Variable to plot\n",
    "EXPERIMENTS = ['ctrl_proj_std']  # List of experiments to compare\n",
    "MODELS = ['AWI/PISM1', 'UCIJPL/ISSM', 'NCAR/CISM', 'DOE/MALI']  # List of models to compare\n",
    "\n",
    "# Optional: Select specific time step (None for all)\n",
    "TIME_STEP = 0  # 0 for first time step, None to load all time steps\n",
    "\n",
    "NAN_VALUES = [0]\n",
    "\n",
    "print(f\"Variable: {VARIABLE}\")\n",
    "print(f\"Experiments: {EXPERIMENTS}\")\n",
    "print(f\"Models: {MODELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load File Index\n",
    "\n",
    "Load the ISMIP6 file index to find the URLs for the requested data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file index\n",
    "print(\"Loading ISMIP6 file index...\")\n",
    "df = get_file_index()\n",
    "\n",
    "# Add model column\n",
    "df['model'] = df['institution'] + '/' + df['model_name']\n",
    "\n",
    "print(f\"Total files in index: {len(df):,}\")\n",
    "print(f\"Variables available: {df['variable'].nunique()}\")\n",
    "print(f\"Models available: {df['model'].nunique()}\")\n",
    "print(f\"Experiments available: {df['experiment'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Matching Files\n",
    "\n",
    "Filter the index to find files matching our criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for matching files\n",
    "filtered_df = df[\n",
    "    (df['variable'] == VARIABLE) & \n",
    "    (df['experiment'].isin(EXPERIMENTS)) & \n",
    "    (df['model'].isin(MODELS))\n",
    "]\n",
    "\n",
    "print(f\"Found {len(filtered_df)} matching files:\")\n",
    "print()\n",
    "for _, row in filtered_df.iterrows():\n",
    "    size_mb = row['size_bytes'] / (1024 * 1024)\n",
    "    print(f\"  {row['model']:20} | {row['experiment']:20} | {size_mb:6.1f} MB\")\n",
    "\n",
    "if len(filtered_df) == 0:\n",
    "    print(\"\\n⚠️  No files found matching the criteria!\")\n",
    "    print(\"\\nTry checking available combinations:\")\n",
    "    for model in MODELS:\n",
    "        model_df = df[(df['model'] == model) & (df['variable'] == VARIABLE)]\n",
    "        if len(model_df) > 0:\n",
    "            print(f\"  {model}: {', '.join(model_df['experiment'].unique())}\")\n",
    "        else:\n",
    "            print(f\"  {model}: No data for variable {VARIABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NetCDF Data\n",
    "\n",
    "Load the data directly from Google Cloud Storage using xarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from each file\n",
    "datasets = {}\n",
    "\n",
    "for _, row in filtered_df.iterrows():\n",
    "    model = row['model']\n",
    "    experiment = row['experiment']\n",
    "    url = row['url']\n",
    "    \n",
    "    key = f\"{model} - {experiment}\"\n",
    "    \n",
    "    print(f\"Loading {key}...\")\n",
    "    \n",
    "    try:\n",
    "        # Open dataset from GCS\n",
    "        ds = xr.open_dataset(url, engine='h5netcdf')\n",
    "        \n",
    "        # Apply grid correction if needed\n",
    "        ds = correct_grid_coordinates(ds, data_var=VARIABLE)\n",
    "\n",
    "        # Replace specified NaN values with actual NaN\n",
    "        if VARIABLE in ds:\n",
    "            for nan_val in NAN_VALUES:\n",
    "                ds[VARIABLE] = ds[VARIABLE].where(ds[VARIABLE] != nan_val, np.nan)\n",
    "        \n",
    "        # Get the variable data\n",
    "        if VARIABLE in ds:\n",
    "            var_data = ds[VARIABLE]\n",
    "            \n",
    "            # Select specific time step if requested\n",
    "            if TIME_STEP is not None and 'time' in var_data.dims:\n",
    "                var_data = var_data.isel(time=TIME_STEP)\n",
    "            \n",
    "            datasets[key] = var_data\n",
    "            \n",
    "            # Print info\n",
    "            print(f\"  Shape: {var_data.shape}\")\n",
    "            print(f\"  Dimensions: {list(var_data.dims)}\")\n",
    "            print(f\"  Coordinates: {list(var_data.coords)}\")\n",
    "            if hasattr(var_data, 'units'):\n",
    "                print(f\"  Units: {var_data.units}\")\n",
    "        else:\n",
    "            print(f\"  ⚠️  Variable {VARIABLE} not found in dataset\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error loading data: {e}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(datasets)} datasets successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Global Value Range\n",
    "\n",
    "For consistent colorbars across all plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate global min/max for consistent color scale\n",
    "if len(datasets) > 0:\n",
    "    all_values = []\n",
    "    for key, data in datasets.items():\n",
    "        # Sample the data to avoid loading entire arrays\n",
    "        values = data.values.flatten()\n",
    "        # Remove NaN and infinite values\n",
    "        valid_values = values[np.isfinite(values)]\n",
    "        if len(valid_values) > 0:\n",
    "            all_values.extend(valid_values)\n",
    "    \n",
    "    if len(all_values) > 0:\n",
    "        vmin = np.percentile(all_values, 5)\n",
    "        vmax = np.percentile(all_values, 95)\n",
    "        print(f\"Value range: {vmin:.2e} to {vmax:.2e}\")\n",
    "        if vmin < 0 and vmax > 0:\n",
    "            abs_max = max(abs(vmin), abs(vmax))\n",
    "            vmin, vmax = -abs_max, abs_max\n",
    "            print(f\"Adjusted to symmetric range around zero: {vmin:.2e} to {vmax:.2e}\")\n",
    "            cmap = 'RdBu_r'\n",
    "        elif (np.abs(vmax) > np.abs(vmin)) and np.abs(vmin) < 1:\n",
    "            vmin = 0\n",
    "            cmap = 'blues'\n",
    "        elif (np.abs(vmin) > np.abs(vmax)) and np.abs(vmax) < 1:\n",
    "            vmax = 0\n",
    "            cmap = 'blues_r'\n",
    "        else:\n",
    "            cmap = 'viridis'\n",
    "\n",
    "    else:\n",
    "        vmin, vmax = None, None\n",
    "        print(\"No valid values found\")\n",
    "else:\n",
    "    vmin, vmax = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Interactive Plots\n",
    "\n",
    "Generate HoloViews plots with linked axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots with linked axes\n",
    "plots = []\n",
    "\n",
    "# Find the common x and y range across all datasets to ensure linking works\n",
    "all_x_coords = []\n",
    "all_y_coords = []\n",
    "for key, data in datasets.items():\n",
    "    all_x_coords.append(data.x.values)\n",
    "    all_y_coords.append(data.y.values)\n",
    "\n",
    "# Use the first dataset's coordinates as the reference (they should all be the same grid)\n",
    "x_coords = all_x_coords[0]\n",
    "y_coords = all_y_coords[0]\n",
    "x_range = (float(x_coords.min()), float(x_coords.max()))\n",
    "y_range = (float(y_coords.min()), float(y_coords.max()))\n",
    "\n",
    "print(f\"Common x range: {x_range}\")\n",
    "print(f\"Common y range: {y_range}\")\n",
    "print()\n",
    "\n",
    "for i, (key, data) in enumerate(datasets.items()):\n",
    "    print(f\"Creating plot for {key}...\")\n",
    "    \n",
    "    # Create HoloViews Image directly from the data with explicit bounds\n",
    "    # This ensures all plots use the same coordinate system\n",
    "    # Note: Flip the array vertically to match the coordinate system\n",
    "    img = hv.Image(\n",
    "        np.flipud(data.values),\n",
    "        bounds=(x_range[0], y_range[0], x_range[1], y_range[1]),\n",
    "        kdims=['x', 'y'],\n",
    "        vdims=[data.name or 'value']\n",
    "    ).opts(\n",
    "        cmap=cmap,\n",
    "        clim=(vmin, vmax),\n",
    "        title=key,\n",
    "        width=300,\n",
    "        colorbar=True,\n",
    "        tools=['hover', 'pan', 'wheel_zoom', 'box_zoom', 'reset'],\n",
    "        xlabel='X (m)',\n",
    "        ylabel='Y (m)',\n",
    "        aspect='equal',\n",
    "        data_aspect=1,\n",
    "        fontsize={'title': 12, 'labels': 10, 'xticks': 8, 'yticks': 8}\n",
    "    )\n",
    "    \n",
    "    plots.append(img)\n",
    "\n",
    "print(f\"\\nCreated {len(plots)} plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Linked Plots\n",
    "\n",
    "All plots share the same x and y ranges, so zooming in one will zoom all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(plots) > 0:\n",
    "    # Arrange plots in a grid\n",
    "    if len(plots) == 1:\n",
    "        layout = plots[0]\n",
    "    elif len(plots) == 2:\n",
    "        layout = plots[0] + plots[1]\n",
    "    else:\n",
    "        # Create a grid layout for more than 2 plots\n",
    "        layout = hv.Layout(plots).cols(2)\n",
    "    \n",
    "    # Link the axes across all plots\n",
    "    layout.opts(\n",
    "        opts.Image(axiswise=False),  # Share axes\n",
    "        opts.Layout(shared_axes=True)  # Link all axes\n",
    "    )\n",
    "    \n",
    "    display(layout)\n",
    "else:\n",
    "    print(\"No plots to display. Please check the configuration and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information\n",
    "\n",
    "Display metadata about the loaded datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed information about each dataset\n",
    "for key, data in datasets.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Dataset: {key}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    print(f\"Dimensions: {list(data.dims)}\")\n",
    "    print(f\"Sizes: {', '.join([f'{dim}={size}' for dim, size in data.sizes.items()])}\")\n",
    "    print(f\"Coordinates: {list(data.coords)}\")\n",
    "    \n",
    "    # Display attributes\n",
    "    if len(data.attrs) > 0:\n",
    "        print(\"\\nAttributes:\")\n",
    "        for attr, value in data.attrs.items():\n",
    "            print(f\"  {attr}: {value}\")\n",
    "    \n",
    "    # Display statistics\n",
    "    values = data.values.flatten()\n",
    "    valid_values = values[np.isfinite(values)]\n",
    "    if len(valid_values) > 0:\n",
    "        print(\"\\nStatistics:\")\n",
    "        print(f\"  Min: {np.min(valid_values):.2e}\")\n",
    "        print(f\"  Max: {np.max(valid_values):.2e}\")\n",
    "        print(f\"  Mean: {np.mean(valid_values):.2e}\")\n",
    "        print(f\"  Median: {np.median(valid_values):.2e}\")\n",
    "        print(f\"  Valid cells: {len(valid_values):,} / {len(values):,} ({100*len(valid_values)/len(values):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Interactive Exploration\n",
    "\n",
    "- **Pan**: Click and drag to pan around\n",
    "- **Zoom**: Scroll wheel to zoom in/out\n",
    "- **Box Zoom**: Use the box zoom tool to select a region\n",
    "- **Reset**: Click reset button to return to original view\n",
    "- **Hover**: Hover over the plot to see exact values\n",
    "- **Linked Views**: All plots zoom and pan together!\n",
    "\n",
    "To change the comparison, modify the configuration in the second cell and re-run all cells."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ismip-comparison-tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
