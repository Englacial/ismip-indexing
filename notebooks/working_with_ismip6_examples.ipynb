{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3470624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import cftime\n",
    "\n",
    "import ismip6_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d563e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f58be",
   "metadata": {},
   "source": [
    "## Loading ISMIP6 Antarctica outputs\n",
    "\n",
    "* ISMIP6 Antarctica outputs are ~1.1 TB in total. Officially, they are available through Globus, but we've pulled the whole dataset and put it on GCloud at `gs://ismip6/` (byte-for-byte identical -- we don't want to be responsible for hosting modified versions of things like this).\n",
    "* Following CMIP conventions, every variable is a separate NetCDF file. Nominally, these are CF-compliant and follow a standardized set of file and variable naming rules, but, following CMIP conventions ðŸ™‚, there are a scattering of errors. See the [ISMIP6 output specifications](https://theghub.org/groups/ismip6/wiki/MainPage/ISMIP6ProjectionsAntarctica).\n",
    "* All of the outputs are uniform rectangular grids in EPSG:3031 projection, but there are multiple resolutions.\n",
    "\n",
    "\n",
    "Ideally, lazy loading of this dataset should be easy and concise. We would like loading a dataset like this into an Xarray DataTree to be a two line operation:\n",
    "\n",
    "```python\n",
    "catalog = helper_library.open(\"gs://lightweight-reference-file\")\n",
    "# If desired, filter the catalog\n",
    "dt = catalog.to_datatree()\n",
    "```\n",
    "\n",
    "Where there are two important properties we care about here:\n",
    "\n",
    "1. We want to be able to create `lightweight-reference-file` for an existing dataset without needing to change the underlying bytes\n",
    "2. We want to be able to encode \"fixes\" somewhere before it becomes an Xarray DataTree -- \"fixes\" are things like different variable naming conventions, misspelled files, incorrect time axes, etc.\n",
    "\n",
    "The code below actually loads the ISMIP6 outputs into a DataTree. It's a bit more than two lines.\n",
    "\n",
    "The main issues are inconsistencies in the output files. For example:\n",
    "* A few files are mis-named (missing an underscore) â†’ corrected by `ismip6_helper.get_file_index()`\n",
    "* Some grids were defined with `x` and `y` coordinates (in EPSG:3031 projection) while others were specified by `lat`, `lon` points â†’ corrected by `ismip6_helper.correct_grid_coordinates()`\n",
    "* Timestamps are specified in a variety of different formats with various CF-compliance issues â†’ fixed by `ismip6_helper.open_ismip6_dataset()` which automatically detects and corrects:\n",
    "  - Typo: `unit` instead of `units` attribute\n",
    "  - Invalid use `MM-DD-YYYY` instead of `YYYY-MM-DD`\n",
    "  - Invalid dates (e.g., day 0 â†’ day 1)\n",
    "  - etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe index by scanning the ISMIP6 Antarctica output files\n",
    "# This is ~200 lines of code to build an index of ISMIP6 data files from the filenames\n",
    "ismip6_df = ismip6_helper.get_file_index()\n",
    "\n",
    "# For the purposes of this demo, filter down the number of files we have to load\n",
    "ismip6_df = ismip6_df.query('experiment in [\"ctrl_proj_std\", \"exp05\", \"ctrl_proj\"] and variable in [\"lithk\", \"base\", \"sftgrf\"] and institution in [\"JPL1\", \"AWI\", \"DOE\"]')\n",
    "\n",
    "# Build a DataTree of the outputs\n",
    "datasets = {}\n",
    "for _, row in ismip6_df.iterrows():\n",
    "    try:\n",
    "        p = f'{row[\"institution\"]}_{row[\"model_name\"]}/{row[\"experiment\"]}/{row[\"variable\"]}' # DataTree path\n",
    "        \n",
    "        # Use the new helper function that automatically fixes time encoding issues\n",
    "        ds = ismip6_helper.open_ismip6_dataset(row[\"url\"], chunks={'time': 1})\n",
    "        ds = ismip6_helper.correct_grid_coordinates(ds, data_var=row[\"variable\"])\n",
    "\n",
    "        datasets[p] = ds\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {p}: {e}\")\n",
    "        \n",
    "ismip6_dt = xr.DataTree.from_dict(datasets)\n",
    "\n",
    "#ismip6_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f132d",
   "metadata": {},
   "source": [
    "### Select and plot one variable\n",
    "\n",
    "Once we have the DataTree loaded, we can easily filter down to variables of interest: `ismip6_dt['JPL1_ISSM']['exp05']['lithk']`\n",
    "\n",
    "**This part works well enough.**\n",
    "\n",
    "The example below produces a plot of the change in ie thickness since the beginning of the simulation. So far, we've only lazily loaded the data, so the actual data hasn't been downloaded. We call `.compute()` on the thickness change variable to force loading of the data in order to make the interactive plot responsive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fedaf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one dataset from the DataTree\n",
    "dt = ismip6_dt['JPL1_ISSM']['exp05']['lithk']\n",
    "\n",
    "# Compute the change in thickness relative to the first time step\n",
    "# Since the datasets are lazily loaded, we now want to actually force computation of a result\n",
    "# so that the interactive plot will be responsive.\n",
    "delta_thickness = (dt['lithk'] - dt['lithk'].isel(time=0)).rename('delta_lithk').compute()\n",
    "\n",
    "# Determine a useful color scale range\n",
    "vmag = np.max(np.abs(delta_thickness.quantile([0.01, 0.99]).values))\n",
    "\n",
    "# Plot with a slider to change the date\n",
    "delta_thickness.hvplot.image(x='x', y='y', clim=(-vmag, vmag), cmap='RdBu').opts(\n",
    "        aspect='equal',\n",
    "        title=\"Change in ice thickness relative to the first timestep\",\n",
    "        colorbar_opts={'title': 'Change in thickness (m)'},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebade53",
   "metadata": {},
   "source": [
    "### Regridding multiple models to a common comparison grid\n",
    "\n",
    "While all of the ISMIP6 outputs were interpolated to a regular grid, these grids have different resolutions. So if we want to do any cross-model comparison, we need to get things onto a common grid.\n",
    "\n",
    "We have some more complicated ideas about how to do regridding, but we also want to make sure that simple things work.\n",
    "\n",
    "Ideally, it would be possible to call `interp` on a DataTree like this:\n",
    "\n",
    "```python\n",
    "comparison_grid = xr.Dataset({\n",
    "    'x': (['x'], np.arange(-3040e3, 3040e3, 16e3)),\n",
    "    'y': (['y'], np.arange(-3040e3, 3040e3, 16e3)),\n",
    "    'time': (['time'], xr.date_range('2016-01-01', '2100-12-31', freq='10Y').values),\n",
    "})\n",
    "\n",
    "ismip6_dt_regridded = ismip6_dt.interp(x=comparison_grid.x, y=comparison_grid.y)\n",
    "```\n",
    "\n",
    "This doesn't actually work yet, but we can use `map_over_datasets` to do the same thing. Not terrible, but could be cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_grid = xr.Dataset({\n",
    "    'x': (['x'], np.arange(-3040e3, 3040e3, 16e3)),\n",
    "    'y': (['y'], np.arange(-3040e3, 3040e3, 16e3)),\n",
    "    'time': (['time'], xr.date_range('2016-01-01', '2100-12-31', freq='10Y').values),\n",
    "})\n",
    "\n",
    "regridded = ismip6_dt.map_over_datasets(\n",
    "    lambda x: x.interp(\n",
    "        x=comparison_grid.x,\n",
    "        y=comparison_grid.y,\n",
    "        time=comparison_grid.time,\n",
    "        method='nearest',\n",
    "        kwargs={'fill_value': np.nan}\n",
    "    ) if ('x' in x.dims and 'y' in x.dims) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df07c612",
   "metadata": {},
   "source": [
    "Now that we're working on a common comparison grid, we can do some cross-model comparison. As an example, we'll plot the standard deviation of the change in ice thickness since the first timestep of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe269f93",
   "metadata": {},
   "source": [
    "```python\n",
    "exp05 = ismip6_dt.subtree['exp05']\n",
    "lithk_subset = exp05.subtree['lithk']\n",
    "\n",
    "# or...\n",
    "\n",
    "lithk_subset = ismpi6_dt.subtree['exp05', 'lithk']\n",
    "\n",
    "lithk.std()\n",
    "lithk.interp(args).std()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd583670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of the change in lithk across models\n",
    "delta_lithk_all = xr.concat([\n",
    "    (node.ds['lithk'].isel(time=slice(1, None)) - node.ds['lithk'].isel(time=0)) \n",
    "    for node in regridded.subtree \n",
    "    if node.path.endswith('exp05/lithk') and node.has_data\n",
    "], dim='model').std(dim='model').compute()\n",
    "\n",
    "delta_lithk_all.hvplot.image(\n",
    "    x='x', y='y', \n",
    "    clim=(0, 200), \n",
    "    cmap='gray_r',\n",
    "    clabel='Std dev of thickness change (m)'\n",
    ").opts(aspect='equal', title='Standard deviation of ice thickness change across models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa99615",
   "metadata": {},
   "source": [
    "### Computed scalars: mass above flotation\n",
    "**TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984020a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ivaf_reference = xr.open_dataset('external_data/ismip6_computed_scalars/computed_ivaf_AIS_JPL1_ISSM_exp05.nc', engine='h5netcdf', decode_times=False)\n",
    "tmp_ivaf_minus_ctrl_reference = xr.open_dataset('external_data/ismip6_computed_scalars/computed_ivaf_minus_ctrl_proj_AIS_JPL1_ISSM_exp05.nc', engine='h5netcdf', decode_times=False)\n",
    "\n",
    "ivaf_reference = xr.merge([tmp_ivaf_reference['ivaf'], tmp_ivaf_minus_ctrl_reference['ivaf'].rename('ivaf_minus_ctrl')])\n",
    "(ivaf_reference - ivaf_reference.isel(time=0)).hvplot.line(\n",
    "    x='time',\n",
    "    ylabel='Cumulative change in volume above flotation (m^3)',\n",
    "    title='Ice Volume Above Flotation for JPL1_ISSM exp05'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604034f",
   "metadata": {},
   "source": [
    "\n",
    "```matlab\n",
    "ivaf_total_region=sum((thickness_i(pos_region)+ocean_density/ice_density*min(bed_i(pos_region),0)).*groundmask_i(pos_region).*mask_i(pos_region).*scalefac_model(pos_region))*(resolution*1000)^2; %in m^3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658db49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_density = 917 # kg/m^3\n",
    "ocean_density = 1028 # kg/m^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the scaling factor for each grid cell in regridded using pyproj\n",
    "# The scaling factor accounts for map projection distortion\n",
    "import pyproj\n",
    "\n",
    "# Create 2D grids for x and y\n",
    "xx, yy = np.meshgrid(comparison_grid.x.values, comparison_grid.y.values)\n",
    "\n",
    "# Set up the projection for EPSG:3031 (Antarctic Polar Stereographic)\n",
    "proj = pyproj.Proj('EPSG:3031')\n",
    "\n",
    "# Convert projected coordinates to lat/lon\n",
    "lons, lats = proj(xx, yy, inverse=True)\n",
    "\n",
    "# Get the factors at each grid point using the Proj object\n",
    "# get_factors returns: (meridional_scale, parallel_scale, areal_scale, \n",
    "#                       angular_distortion, meridian_parallel_angle, \n",
    "#                       meridian_convergence, tissot_semimajor, tissot_semiminor)\n",
    "# We want the areal_scale (index 2)\n",
    "factors = proj.get_factors(lons.ravel(), lats.ravel(), radians=False)\n",
    "areal_scale = factors.areal_scale.reshape(xx.shape)\n",
    "\n",
    "# Create the scaling factor as an xarray DataArray\n",
    "scale_factor = xr.DataArray(\n",
    "    areal_scale,\n",
    "    coords={'y': comparison_grid.y.values, 'x': comparison_grid.x.values},\n",
    "    dims=['y', 'x'],\n",
    "    name='scalefac',\n",
    "    attrs={\n",
    "        'long_name': 'Area scaling factor',\n",
    "        'description': 'Ratio of true area to projected area from pyproj.get_factors',\n",
    "        'units': '1',\n",
    "        'projection': 'EPSG:3031',\n",
    "    }\n",
    ")\n",
    "\n",
    "scale_factor.hvplot.image().opts(aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2cfd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_file = xr.open_dataset('external_data/ismip6_computed_scalars/af2_el_ismip6_ant_01.nc')\n",
    "scale_file_interp = scale_file['af2'].interp(x=comparison_grid.x, y=comparison_grid.y, method='linear')\n",
    "\n",
    "(scale_file_interp - (1/scale_factor)).hvplot.image().opts(aspect='equal', clim=(-0.1, 0.1), title='Difference between computed and reference scaling factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d124eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ismip6_dt.children.keys():\n",
    "    for experiment in ismip6_dt[model].children.keys():\n",
    "        print(f\"{model} - {experiment}\")\n",
    "        dt = ismip6_dt[model][experiment]\n",
    "\n",
    "        lithk = dt['lithk']['lithk']\n",
    "        base = dt['base']['base']\n",
    "        sftgrf = dt['sftgrf']['sftgrf']\n",
    "\n",
    "        resolution = comparison_grid.x[1] - comparison_grid.x[0]  # in meters\n",
    "\n",
    "        ivaf = ((lithk + ocean_density/ice_density * np.minimum(base, 0)) * sftgrf * (1/scale_factor)).sum(dim=['x', 'y']) * (resolution**2)  # in m^3\n",
    "        ivaf = ivaf.rename('ivaf')\n",
    "        ismip6_dt[model][experiment]['ivaf'] = ivaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ivaf = ismip6_dt['JPL1_ISSM']['exp05']['ivaf'].compute()\n",
    "ivaf_minus_ctrl = (ivaf - ismip6_dt['JPL1_ISSM']['ctrl_proj']['ivaf']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = ((ivaf - ivaf.isel(time=0)).hvplot.line(x='time', label='exp05') *\n",
    "        (ivaf_minus_ctrl - ivaf_minus_ctrl.isel(time=0)).hvplot.line(x='time', label='exp05 - ctrl_proj')\n",
    "        ).opts(\n",
    "    ylabel='Cumulative change in\\nvolume above flotation (m^3)',\n",
    "    title='Computed changed in ice volume above flotation for JPL1_ISSM exp05',\n",
    "    legend_position='bottom_left', show_grid=True\n",
    "    )\n",
    "ref = (ivaf_reference - ivaf_reference.isel(time=0)).hvplot.line(\n",
    "    x='time',\n",
    "    ylabel='Cumulative change in\\nvolume above flotation (m^3)',\n",
    "    title='Reference (from doi.org/10.5281/zenodo.3940766)'\n",
    "    ).opts(legend_position='bottom_left', show_grid=True)\n",
    "\n",
    "calc + ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5dfcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ismip6_dt['AWI_PISM1/ctrl_proj_std'].subtree.as_dataset()\n",
    "ismip6_dt['AWI_PISM1/ctrl_proj_std'].subtree.condense()\n",
    "ismip6_dt['AWI_PISM1/ctrl_proj_std'].subtree.gather_leaves() # gather_siblings\n",
    "\n",
    "dt_of_exp05_datasets =ismip6_dt.subtree['exp05'].gather_siblings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ismip6_dt['AWI_PISM1/ctrl_proj_std'].children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ismip6_dt.copy()\n",
    "\n",
    "dt = dt.map_over_datasets(\n",
    "    lambda x: xr.merge([y.to_dataset() for y in x.subtree]) if list(x.subtree.children) == ['base', 'lithk', 'sftgrf'] else x\n",
    ")\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0372c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ismip6_dt['AWI_PISM1/ctrl_proj_std'].as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40615a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([x.to_dataset() for x in ismip6_dt['AWI_PISM1/ctrl_proj_std'].subtree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777805f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ismip-comparison-tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
